# Clauses
# clauses have two fields, the first describes the params, the second is a set of literals separated by a pipe symbol 
# Example:
# x:Number; !P(x) | Q(x)
# The hierarchical planning system currently does not support knowledge with clauses

# Facts
# put simply literals here (all parameters are interpreted as constants)

Thing(null)
#x:Instances,y:Instances; !Instances(x) | !assigned(x,y) | Instances(y)


### FEATURE SELECTION SEARCHER ###

# Best First direction: Option -D {0, 1, 2}[1]
#### BFDirection(0)
BFDirection(1)
#### BFDirection(2)

# Best First searchTermination: Option -N [2, 10][5]i
BFSearchTermination(2)
#### BFSearchTermination(3)
BFSearchTermination(4)
#### BFSearchTermination(5)
BFSearchTermination(6)
#### BFSearchTermination(7)
BFSearchTermination(8)
#### BFSearchTermination(9)
BFSearchTermination(10)

# Greedy Stepwise numToSelect: Option -N [10,1000][30]il
GSNumToSelect(10)
#### GSNumToSelect(20)
GSNumToSelect(30)
#### GSNumToSelect(62)
GSNumToSelect(125)
#### GSNumToSelect(250)
GSNumToSelect(500)
#### GSNumToSelect(1000)

# Greedy Stepwise treshold: Option -T [0, 20] [1]
#### GSThreshold(0)
GSThreshold(1)
#### GSThreshold(4)
GSThreshold(7)
#### GSThreshold(10)
GSThreshold(13)
#### GSThreshold(16)
GSThreshold(20)

# Ranker treshold: Option -T [0.2,10][1]
#### RankThreshold(0.2)
RankThreshold(1)
#### RankThreshold(2)
RankThreshold(3)
#### RankThreshold(4)
RankThreshold(5)
#### RankThreshold(6)
RankThreshold(7)
#### RankThreshold(8)
RankThreshold(9)
#### RankThreshold(10)


### FEATURE SELECTION EVALUATORS ###

# OneR Attribute Evaluation minimumBucketSize: Option -B [1,64][6]il
#### OneRAEMinimumBucketSize(1)
OneRAEMinimumBucketSize(2)
#### OneRAEMinimumBucketSize(4)
OneRAEMinimumBucketSize(6)
#### OneRAEMinimumBucketSize(8)
OneRAEMinimumBucketSize(16)
#### OneRAEMinimumBucketSize(32)
OneRAEMinimumBucketSize(64)

# OneR Attribute Evaluation folds: Option -F [2,15][10]i
OneRAEFolds(2)
#### OneRAEFolds(4)
OneRAEFolds(6)
#### OneRAEFolds(8)
OneRAEFolds(10)
#### OneRAEFolds(12)
OneRAEFolds(14)
#### OneRAEFolds(15)

# Principal Component Analysis varianceCovered: Option -R [0.5, 1.0][0.95]
PCAVarianceCovered(0.5)
#### PCAVarianceCovered(0.55)
PCAVarianceCovered(0.6)
#### PCAVarianceCovered(0.65)
PCAVarianceCovered(0.7)
#### PCAVarianceCovered(0.75)
PCAVarianceCovered(0.8)
#### PCAVarianceCovered(0.85)
#### PCAVarianceCovered(0.9)
PCAVarianceCovered(0.95)
#### PCAVarianceCovered(1.0)

# Principal Component Analysis maximumAttributeNames: Option -A [1, 1024][32]il
#### PCAMaximumAttributeNames(1)
PCAMaximumAttributeNames(2)
#### PCAMaximumAttributeNames(4)
PCAMaximumAttributeNames(8)
#### PCAMaximumAttributeNames(16)
PCAMaximumAttributeNames(32)
#### PCAMaximumAttributeNames(64)
PCAMaximumAttributeNames(128)
#### PCAMaximumAttributeNames(256)
PCAMaximumAttributeNames(512)
#### PCAMaximumAttributeNames(1024)

# ReliefF Attribute Evaluator numberOfNeighbors: Option -K [2,64][10]il
ReliefFAENumNeighbours(1)
#### ReliefFAENumNeighbours(2)
ReliefFAENumNeighbours(4)
ReliefFAENumNeighbours(10)
#### ReliefFAENumNeighbours(8)
ReliefFAENumNeighbours(16)
#### ReliefFAENumNeighbours(32)
ReliefFAENumNeighbours(64)

# ReliefF Attribute Evaluator sigma: Option -A [1,8][2]il
#### ReliefFAESigma(1)
ReliefFAESigma(2)
#### ReliefFAESigma(4)
ReliefFAESigma(8)


### BASE CLASSIFIERS ###

# Bayes Net searchAlgorithm: Option -Q {weka.classifiers.bayes.net.search.local.K2,weka.classifiers.bayes.net.search.local.HillClimber,weka.classifiers.bayes.net.search.local.LAGDHillClimber,weka.classifiers.bayes.net.search.local.SimulatedAnnealing,weka.classifiers.bayes.net.search.local.TabuSearch,weka.classifiers.bayes.net.search.local.TAN} [weka.classifiers.bayes.net.search.local.K2]
BNLocalSearch(weka.classifiers.bayes.net.search.local.K2)
#### BNLocalSearch(weka.classifiers.bayes.net.search.local.HillClimber)
BNLocalSearch(weka.classifiers.bayes.net.search.local.LAGDHillClimber)
#### BNLocalSearch(weka.classifiers.bayes.net.search.local.SimulatedAnnealing)
BNLocalSearch(weka.classifiers.bayes.net.search.local.TabuSearch)
#### BNLocalSearch(weka.classifiers.bayes.net.search.local.TAN)

# GP tolerance: Option -L [0.0001, 1] [0.1]l
GPTolerance(0.0001)
#### GPTolerance(0.001)
GPTolerance(0.01)
#### GPTolerance(0.1)
GPTolerance(1)

# GP filterType: Option -N {0,1,2} [0]
GPFilterType(0)
#### GPFilterType(1)
GPFilterType(2)

# Linear Regression Attribute Selection Method: Option -S {0,1,2} [0]
LinearRAttrSel(0)
#### LinearRAttrSel(1)
LinearRAttrSel(2)

# Linear Regression Ridge: Option -R [1e-7, 10] [1e-7]l
LinearRRidge(0.0000001)
#### LinearRRidge(0.000001)
LinearRRidge(0.00001)
#### LinearRRidge(0.0001)
LinearRRidge(0.001)
#### LinearRRidge(0.01)
LinearRRidge(0.1)
#### LinearRRidge(1)
LinearRRidge(10)

# Logistic Regression Ridge: Option -R [1e-12, 10] [1e-7]l
#### LogisticRRidge(0.000000000001)
LogisticRRidge(0.00000000001)
#### LogisticRRidge(0.0000000001)
LogisticRRidge(0.000000001)
#### LogisticRRidge(0.00000001)
LogisticRRidge(0.0000001)
#### LogisticRRidge(0.000001)
LogisticRRidge(0.00001)
#### LogisticRRidge(0.0001)
LogisticRRidge(0.001)
#### LogisticRRidge(0.01)
LogisticRRidge(0.1)
#### LogisticRRidge(1)
LogisticRRidge(10)

# Multilayer Perceptron Hidden Layer Type: Option -H {a,i,o,t} [a]
NNHiddenLayer(a)
#### NNHiddenLayer(i)
NNHiddenLayer(o)
#### NNHiddenLayer(t)

# Multilayer Perceptron Learning Rate: Option -L [0.1, 1] [0.3]
NNLearningRate(0.1)
#### NNLearningRate(0.2)
NNLearningRate(0.3)
#### NNLearningRate(0.4)
NNLearningRate(0.5)
#### NNLearningRate(0.6)
NNLearningRate(0.7)
#### NNLearningRate(0.8)
NNLearningRate(0.9)
#### NNLearningRate(1)

# Multilayer Perceptron Momentum: Option -M [0.1, 1] [0.2]
NNMomentum(0.1)
#### NNMomentum(0.2)
NNMomentum(0.3)
#### NNMomentum(0.4)
NNMomentum(0.5)
#### NNMomentum(0.6)
NNMomentum(0.7)
#### NNMomentum(0.8)
NNMomentum(0.9)
#### NNMomentum(1.0)

# SGD Learning Rate: Option -F {0,1,2}[0]
SGDLossFunction(0)
#### SGDLossFunction(1)
SGDLossFunction(2)

# SGD Learning Rate: Option -L [0.00001, 0.1] [0.01]l
SGDLearningRate(0.00001)
#### SGDLearningRate(0.0001)
SGDLearningRate(0.001)
#### SGDLearningRate(0.01)
SGDLearningRate(0.1)

# SGD Lambda: Option -R [1e-12, 10] [1e-4]l
#### SGDLambda(0.000000000001)
SGDLambda(0.00000000001)
#### SGDLambda(0.0000000001)
SGDLambda(0.000000001)
#### SGDLambda(0.00000001)
SGDLambda(0.0000001)
#### SGDLambda(0.000001)
SGDLambda(0.00001)
#### SGDLambda(0.0001)
SGDLambda(0.001)
#### SGDLambda(0.01)
SGDLambda(0.1)
#### SGDLambda(1)
SGDLambda(10)

# Simple Logistic Regression Weight Trim Beta: Option -W [0,1][0]
SLROptsWeightTrim(0.0)
#### SLROptsWeightTrim(0.1)
SLROptsWeightTrim(0.2)
#### SLROptsWeightTrim(0.3)
SLROptsWeightTrim(0.4)
#### SLROptsWeightTrim(0.5)
SLROptsWeightTrim(0.6)
#### SLROptsWeightTrim(0.7)
SLROptsWeightTrim(0.8)
#### SLROptsWeightTrim(0.9)
SLROptsWeightTrim(1.0)

# SMO, SMOreg complexity: Option -C [0.5,1.5][1.0]
SMOComplexity(0.5)
#### SMOComplexity(0.6)
SMOComplexity(0.7)
#### SMOComplexity(0.8)
SMOComplexity(0.9)
#### SMOComplexity(1.0)
SMOComplexity(1.1)
#### SMOComplexity(1.2)
SMOComplexity(1.3)
#### SMOComplexity(1.4)
SMOComplexity(1.5)

# SMO, SMOreg filterType: Option -N {0,1,2} [0]
SMOFilterType(0)
SMOFilterType(1)
#### SMOFilterType(2)

# GP, SMO, SMOreg kernel: Option -K {weka.classifiers.functions.supportVector.NormalizedPolyKernel,weka.classifiers.functions.supportVector.PolyKernel,weka.classifiers.functions.supportVector.Puk,weka.classifiers.functions.supportVector.RBFKernel}[weka.classifiers.functions.supportVector.NormalizedPolyKernel]
Kernel(weka.classifiers.functions.supportVector.NormalizedPolyKernel)
#### Kernel(weka.classifiers.functions.supportVector.PolyKernel)
Kernel(weka.classifiers.functions.supportVector.Puk)
#### Kernel(weka.classifiers.functions.supportVector.RBFKernel)

# SMOreg regOptimizer: Option -I {weka.classifiers.functions.supportVector.RegSMOImproved}[weka.classifiers.functions.supportVector.RegSMOImproved]
RegOptimizer(weka.classifiers.functions.supportVector.RegSMOImproved)

# Poly exponent: Option -E [0.2, 5] [1.0]
PolyKernelExponent(0.2)
#### PolyKernelExponent(1.0)
PolyKernelExponent(1.8)
#### PolyKernelExponent(2.6)
PolyKernelExponent(3.4)
#### PolyKernelExponent(4.2)
PolyKernelExponent(5.0)

# Puk sigma: Option -S [0.1, 10] [1.0]
PukKernelSigma(0.1)
PukKernelSigma(1)
#### PukKernelSigma(2)
PukKernelSigma(3)
#### PukKernelSigma(4)
PukKernelSigma(5)
#### PukKernelSigma(6)
PukKernelSigma(7)
#### PukKernelSigma(8)
PukKernelSigma(9)
#### PukKernelSigma(10)

# Puk omega: Option -O [0.1, 1] [1.0]
#### PukKernelOmega(0.1)
PukKernelOmega(0.2)
#### PukKernelOmega(0.3)
PukKernelOmega(0.4)
#### PukKernelOmega(0.5)
PukKernelOmega(0.6)
#### PukKernelOmega(0.7)
PukKernelOmega(0.8)
#### PukKernelOmega(0.9)
PukKernelOmega(1.0)

# RBF gamma: Option -G [0.0001,1] [0.01]l
RBFKernelGamma(0.0001
#### RBFKernelGamma(0.001
RBFKernelGamma(0.01
#### RBFKernelGamma(0.1
RBFKernelGamma(1.0

# Voted Perceptron Exponent: Option -E [0.2, 5] [1.0]
VPExponent(0.2)
#### VPExponent(1.0)
VPExponent(1.8)
#### VPExponent(2.6)
VPExponent(3.4)
#### VPExponent(4.2)
VPExponent(5.0)

# Voted Perceptron Iterations: Option -I [1, 10] [1]i
VPIterations(1)
#### VPIterations(2)
VPIterations(3)
#### VPIterations(4)
VPIterations(5)
#### VPIterations(6)
VPIterations(7)
#### VPIterations(8)
VPIterations(9)
#### VPIterations(10)

# Voted Perceptron maxK: Option -M [5000, 50000] [10000]il
VPMaxK(5000)
#### VPMaxK(10000)
VPMaxK(20000)
#### VPMaxK(50000)

# KNN numberOfNeighbors: Option -K [1,64] [1]il
KNNKNN(1)
#### KNNKNN(2)
KNNKNN(4)
#### KNNKNN(8)
KNNKNN(16)
#### KNNKNN(32)
KNNKNN(64)

# KStar globalBlend: Option -B [1,100] [20]i
KStarGlobalBlend(1)
#### KStarGlobalBlend(10)
KStarGlobalBlend(20)
#### KStarGlobalBlend(30)
KStarGlobalBlend(40)
#### KStarGlobalBlend(50)
KStarGlobalBlend(60)
#### KStarGlobalBlend(70)
KStarGlobalBlend(80)
#### KStarGlobalBlend(90)
KStarGlobalBlend(100)

# KStar missingMode: Option -M {a,d,m,n} [a]
KStarMissingMode(a)
#### KStarMissingMode(d)
KStarMissingMode(m)
#### KStarMissingMode(n)

# Decision Table evaluationMeasure: Option -E {acc,rmse,mae,auc} [acc]
DecTableEvalMeasure(acc)
#### DecTableEvalMeasure(rmse)
DecTableEvalMeasure(mae)
#### DecTableEvalMeasure(auc)

# Decision Table search: Option -S {weka.attributeSelection.BestFirst,weka.attributeSelection.GreedyStepwise,weka.attributeSelection.Ranker}[weka.attributeSelection.BestFirst]
DecTableSearch(weka.attributeSelection.BestFirst)
DecTableSearch(weka.attributeSelection.GreedyStepwise)
#DecTableSearch(weka.attributeSelection.Ranker) #### leads to exception in execution

# Decision Table crossVal: Option -X {1,2,3,4} [1]
DecTableCrossVal(1)
#### DecTableCrossVal(2)
DecTableCrossVal(3)
#### DecTableCrossVal(4)

# Ripper Rules minNo: Option -N [1, 5] [2.0]
RipperMinNo(1.0)
#### RipperMinNo(1.5)
RipperMinNo(2.0)
#### RipperMinNo(2.5)
RipperMinNo(3.0)
#### RipperMinNo(3.5)
RipperMinNo(4.0)
#### RipperMinNo(4.5)
RipperMinNo(5.0)

# Ripper Rules optimizations: Option -O [1,5][2]i
RipperOptimizations(1)
#### RipperOptimizations(2)
RipperOptimizations(3)
#### RipperOptimizations(4)
RipperOptimizations(5)

# M5 Rules minNumInstances: Option -M [1,64][4]il
M5RulesMinNumInstances(1)
#### M5RulesMinNumInstances(2)
M5RulesMinNumInstances(4)
#### M5RulesMinNumInstances(8)
M5RulesMinNumInstances(16)
#### M5RulesMinNumInstances(32)
M5RulesMinNumInstances(64)

# OneR Rules minBucketSize: Option -B [1,32][6]il
OneRMinBucketSize(1)
#### OneRMinBucketSize(2)
OneRMinBucketSize(4)
#### OneRMinBucketSize(8)
OneRMinBucketSize(16)
#### OneRMinBucketSize(32)

# PART Rules minNumObj: Option -M [1,64][2]il
PARTMinNumObj(1)
#### PARTMinNumObj(2)
PARTMinNumObj(4)
#### PARTMinNumObj(8)
PARTMinNumObj(16)
#### PARTMinNumObj(32)
PARTMinNumObj(64)

# PART Rules numFolds: Option -N [2,5][3]i
PARTNumFolds(2)
#### PARTNumFolds(3)
PARTNumFolds(4)
#### PARTNumFolds(5)

# Decision Tree C4.5 minNumObj: Option -M [1, 64][2]il
DTMinNumObj(1)
#### DTMinNumObj(2)
DTMinNumObj(4)
#### DTMinNumObj(8)
DTMinNumObj(16)
#### DTMinNumObj(32)
DTMinNumObj(64)

# Decision Tree C4.5 Confidence Factor: Option -C [0,1][0.25]
## Values over 0.5 give error message that announces that pruning is deactivated
DTConfidenceFactor(0.01)
#### DTConfidenceFactor(0.1)
DTConfidenceFactor(0.2)
#### DTConfidenceFactor(0.3)
DTConfidenceFactor(0.4)
#### DTConfidenceFactor(0.5)
#DTConfidenceFactor(0.6)
#### DTConfidenceFactor(0.7)
#DTConfidenceFactor(0.8)
#### DTConfidenceFactor(0.9)
#DTConfidenceFactor(0.99)

# Logistic Model Tree minNumInstances: Option -M [1,64][15]il
LMTMinNumInstances(1)
#### LMTMinNumInstances(2)
LMTMinNumInstances(4)
#### LMTMinNumInstances(8)
LMTMinNumInstances(16)
#### LMTMinNumInstances(32)
LMTMinNumInstances(64)

# Logistic Model Tree Weight Trim Beta: Option -W [0,1][0]
LMTWeightTrimBeta(0.0)
#### LMTWeightTrimBeta(0.1)
LMTWeightTrimBeta(0.2)
#### LMTWeightTrimBeta(0.3)
LMTWeightTrimBeta(0.4)
#### LMTWeightTrimBeta(0.5)
LMTWeightTrimBeta(0.6)
#### LMTWeightTrimBeta(0.7)
LMTWeightTrimBeta(0.8)
#### LMTWeightTrimBeta(0.9)
LMTWeightTrimBeta(1.0)

# M5Base Tree minNumInstances: Option -M [1,64][4]il
M5PMinNumInstances(1)
#### M5PMinNumInstances(2)
M5PMinNumInstances(4)
#### M5PMinNumInstances(8)
M5PMinNumInstances(16)
#### M5PMinNumInstances(32)
M5PMinNumInstances(64)

# Random Forest numIterations: Option -I [2, 256][10]il
RFNumIterations(2)
RFNumIterations(4)
#### RFNumIterations(8)
RFNumIterations(10)
#### RFNumIterations(16)
RFNumIterations(32)
#### RFNumIterations(64)
RFNumIterations(128)
#### RFNumIterations(256)

# Random Forest numFeatures: Option -K [1, 32][2]il
RFNumFeatures(0)
#### RFNumFeatures(1)
RFNumFeatures(2)
#### RFNumFeatures(4)
RFNumFeatures(8)
#### RFNumFeatures(16)
RFNumFeatures(32)

# Random Forest maxDepth: Option -depth [1, 20][2]i
RFMaxDepth(1)
#### RFMaxDepth(2)
RFMaxDepth(4)
#### RFMaxDepth(6)
RFMaxDepth(8)
#### RFMaxDepth(10)
RFMaxDepth(12)
#### RFMaxDepth(14)
RFMaxDepth(16)
#### RFMaxDepth(18)
RFMaxDepth(20)

# Random Tree KValue: Option -K [2, 32][2]il
RTKValue(2)
#### RTKValue(4)
RTKValue(8)
#### RTKValue(16)
RTKValue(32)

# Random Tree minNum: Option -M [1, 64][1]il
RTMinNum(1)
#### RTMinNum(2)
RTMinNum(4)
#### RTMinNum(8)
RTMinNum(16)
#### RTMinNum(32)
RTMinNum(64)

# Random Tree numFolds: Option -N [2, 5][3]i
#### RTNumFolds(2)
RTNumFolds(3)
#### RTNumFolds(4)
RTNumFolds(5)

# Random Tree maxDepth: Option -depth [2, 20][2]i
RTMaxDepth(2)
#### RTMaxDepth(4)
RTMaxDepth(6)
#### RTMaxDepth(8)
RTMaxDepth(10)
#### RTMaxDepth(12)
RTMaxDepth(14)
#### RTMaxDepth(16)
RTMaxDepth(18)
#### RTMaxDepth(20)

# REP Tree maxDepth: Option -L [2, 20][2]i
REPMaxDepth(2)
REPMaxDepth(4)
#### REPMaxDepth(6)
#### REPMaxDepth(8)
#### REPMaxDepth(10)
REPMaxDepth(12)
#### REPMaxDepth(14)
#### REPMaxDepth(16)
#### REPMaxDepth(18)
REPMaxDepth(20)

# REP Tree minNum: Option -M [1, 64][2]il
REPMinNum(1)
#### REPMinNum(2)
REPMinNum(4)
#### REPMinNum(8)
REPMinNum(16)
#### REPMinNum(32)
REPMinNum(64)

# REP Tree minVarianceProp: Option -V [1e-5, 1e-1][1e-3]l
REPMinVariance(0.00001)
#### REPMinVariance(0.0001)
REPMinVariance(0.001)
#### REPMinVariance(0.01)
REPMinVariance(0.1)


### META CLASSIFIERS ###

# Locally Weighted Learning nearestNeighbourSearch: Option -A {weka.core.neighboursearch.LinearNNSearch} [weka.core.neighboursearch.LinearNNSearch]
LWLNearestNeighbourSearch(weka.core.neighboursearch.LinearNNSearch)

# Locally Weighted Learning KNN: Option -K {-1,10,30,60,90,120} [-1]
LWLKNN(-1)
LWLKNN(10)
#### LWLKNN(30)
LWLKNN(60)
#### LWLKNN(90)
LWLKNN(120)

# Locally Weighted Learning weighingKernel: Option -U {0,1,2,3,4} [0]
LWLWeighingKernel(0)
#### LWLWeighingKernel(1)
LWLWeighingKernel(2)
#### LWLWeighingKernel(3)
LWLWeighingKernel(4)

# AdaBoost numIterations: Option -I [2,128][10]il
AdaBoostNumIterations(2)
#### AdaBoostNumIterations(4)
AdaBoostNumIterations(8)
#### AdaBoostNumIterations(10)
AdaBoostNumIterations(16)
#### AdaBoostNumIterations(32)
AdaBoostNumIterations(64)
#### AdaBoostNumIterations(128)

# AdaBoost weightThreshold: Option -P [50,100][100]i
AdaBoostWeightThreshold(50)
#### AdaBoostWeightThreshold(60)
AdaBoostWeightThreshold(70)
#### AdaBoostWeightThreshold(80)
AdaBoostWeightThreshold(90)
#### AdaBoostWeightThreshold(100)

# Additive Regression numIterations: Option -I [2,128][10]il
AddRegNumIterations(2)
#### AddRegNumIterations(4)
AddRegNumIterations(8)
#### AddRegNumIterations(10)
AddRegNumIterations(16)
#### AddRegNumIterations(32)
AddRegNumIterations(64)
#### AddRegNumIterations(128)

# Additive Regression shrinkage: Option -S [0,1.0][1]
AddRegShrinkage(0.0)
#### AddRegShrinkage(0.1)
AddRegShrinkage(0.2)
#### AddRegShrinkage(0.3)
AddRegShrinkage(0.4)
#### AddRegShrinkage(0.5)
AddRegShrinkage(0.6)
#### AddRegShrinkage(0.7)
AddRegShrinkage(0.8)
#### AddRegShrinkage(0.9)
AddRegShrinkage(1.0)

# Bagging numIterations: Option -I [2,128][10]il
BaggingNumIterations(2)
#### BaggingNumIterations(4)
BaggingNumIterations(8)
#### BaggingNumIterations(10)
BaggingNumIterations(16)
#### BaggingNumIterations(32)
BaggingNumIterations(64)
#### BaggingNumIterations(128)

# Bagging bagSizePercent: Option -P [10,200][100]i
BaggingBagSizePercent(10)
#### BaggingBagSizePercent(25)
BaggingBagSizePercent(50)
#### BaggingBagSizePercent(75)
BaggingBagSizePercent(100)
#### BaggingBagSizePercent(125)
BaggingBagSizePercent(150)
#### BaggingBagSizePercent(175)
BaggingBagSizePercent(200)

# LogitBoost numIterations: Option -I [2,128][10]il
LogitBoostNumIterations(2)
#### LogitBoostNumIterations(4)
LogitBoostNumIterations(8)
#### LogitBoostNumIterations(10)
LogitBoostNumIterations(16)
#### LogitBoostNumIterations(32)
LogitBoostNumIterations(64)
#### LogitBoostNumIterations(128)

# LogitBoost shrinkage: Option -S [0,1.0][1]
LogitBoostShrinkage(0.0)
#### LogitBoostShrinkage(0.1)
LogitBoostShrinkage(0.2)
#### LogitBoostShrinkage(0.3)
LogitBoostShrinkage(0.4)
#### LogitBoostShrinkage(0.5)
LogitBoostShrinkage(0.6)
#### LogitBoostShrinkage(0.7)
LogitBoostShrinkage(0.8)
#### LogitBoostShrinkage(0.9)
LogitBoostShrinkage(1.0)

# LogitBoost numRuns: Option -R [1,5][1]i
LogitBoostNumRuns(1)
#### LogitBoostNumRuns(2)
LogitBoostNumRuns(3)
#### LogitBoostNumRuns(4)
LogitBoostNumRuns(5)

# LogitBoost numFolds: Option -F [1,5][1]i
LogitBoostNumFolds(1)
#### LogitBoostNumFolds(2)
LogitBoostNumFolds(3)
#### LogitBoostNumFolds(4)
LogitBoostNumFolds(5)

# LogitBoost weightThreshold: Option -P [50,100][100]i
LogitBoostWeightThreshold(50)
#### LogitBoostWeightThreshold(60)
LogitBoostWeightThreshold(70)
#### LogitBoostWeightThreshold(80)
LogitBoostWeightThreshold(90)
#### LogitBoostWeightThreshold(100)

# MultiClass Classifier method: Option -M {0,1,2,3} [0]
MCCMethod(0)
MCCMethod(1)
MCCMethod(2)
MCCMethod(3)

# MultiClass Classifier randomWidthFactor: Option -R [0.5,4][2.0]
MCCRandomWidthFactor(0.5)
#### MCCRandomWidthFactor(1.0)
MCCRandomWidthFactor(1.5)
#### MCCRandomWidthFactor(2.0)
MCCRandomWidthFactor(2.5)
#### MCCRandomWidthFactor(3.0)
MCCRandomWidthFactor(3.5)
#### MCCRandomWidthFactor(4.0)

# Random Comittee numIterations: Option -I [2, 64][10]il
RandomComitteeNumIterations(2)
#### RandomComitteeNumIterations(4)
RandomComitteeNumIterations(8)
#### RandomComitteeNumIterations(10)
RandomComitteeNumIterations(16)
#### RandomComitteeNumIterations(32)
RandomComitteeNumIterations(64)

# Random Subspace numIterations: Option -I [2, 64][10]il
RandomSubspaceNumIterations(2)
#### RandomSubspaceNumIterations(4)
RandomSubspaceNumIterations(8)
#### RandomSubspaceNumIterations(10)
RandomSubspaceNumIterations(16)
#### RandomSubspaceNumIterations(32)
RandomSubspaceNumIterations(64)

# Random Subspace subSpaceSize: Option -P [0.1,1.0] [0.5]
RandomSubspaceSubSpaceSizePercent(0.1)
#### RandomSubspaceSubSpaceSizePercent(0.2)
RandomSubspaceSubSpaceSizePercent(0.3)
#### RandomSubspaceSubSpaceSizePercent(0.4)
RandomSubspaceSubSpaceSizePercent(0.5)
#### RandomSubspaceSubSpaceSizePercent(0.6)
RandomSubspaceSubSpaceSizePercent(0.7)
#### RandomSubspaceSubSpaceSizePercent(0.8)
RandomSubspaceSubSpaceSizePercent(0.9)
#### RandomSubspaceSubSpaceSizePercent(1.0)


### ENSEMBLE CLASSIFIERS ###

# Voting combinationRule: Option -R {AVG,PROD,MAJ,MIN,MAX} [AVG]
VoteCombinationRule(AVG)
#### VoteCombinationRule(PROD)
VoteCombinationRule(MAJ)
#### VoteCombinationRule(MIN)
VoteCombinationRule(MAX)